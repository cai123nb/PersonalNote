# 线程安全与锁优化
## 线程安全
`<<Java Concurrency In Practice>>`作者Brian Goetz对`线程安全`的定义: 当多个线程访问一个对象时, 如果不用考虑这些线程在运行时环境下的调度和交替执行, 也不需要进行额外的同步, 或者在调用方法进行任何其他的协调操作, 调用这个对象的行为都能获得正确的结果, 那这个对象是线程安全的.

这个定义比较严谨, 它要求线程安全的代码都必须具备一个特征: 代码本身封装了所有必要的正确性保障手段(如互斥同步等), 令调用者无须关心多线程的问题, 更无须自己采用任何措施来保证多线程的正确调用. 这点听起来比较简单, 但是其实并不容易实现. 在大多数的场景下, 我们都会将这个定义弱化一些, 如果`调用这个对象的行为`限定为`单次调用`, 这个定义的其他描述也能成了的话, 我们就可以称它为线程安全的.

### Java语言中的线程安全
这里讨论的线程安全, 就限定于多个线程之间存在共享数据访问这个前提, 因为如果一段代码根本不会与其他线程共享数据, 那么从线程安全的角度来说, 程序是串行还是多线程执行多它来说都是没有区别的. 我们按照线程安全的`安全程度`由强到弱进行排序, 我们可以将Java语言中各种操作共享的数据分为以下5类: 不可变, 绝对线程安全, 相对线程安全, 线程兼容和线程独立.

#### 不可变
`不可变(Immutable)的对象`一定是线程安全的, 无论是对象的方法实现还是方法的调用者, 都不要采用任何的线程安全的保障措施, 就在前面讲解final时提到的: 只要一个不可变对象被正确的构建出来(没有发生this引用逃逸), 那其外部可见性永远不会改变, 永远也不会看到它在多个线程之中处于不一致的状态. `不可变`带来的安全性是最简单和最纯粹的.

Java语言中, 如果共享数据是一个基本数据类型, 那么只要定义时使用final关键字修饰它就可以保证它是不变的. 如果共享数据是一个对象, 那就需要保证对象的行为不会对其状态产生任何影响才行. 如java.lang.String类对象, 它是一个典型的不可变对象, 我们调用它的substring(), replace()和concat()这些方法都不会影响才行, 都不会影响原来的值, 只会返回一个新构造的字符串对象.

保证对象行为不影响自己状态的途径有很多种, 最简单的方法就是把对象中带有状态的变量都声明为final, 这样在构造函数结束之后, 它就是不可变的.

#### 绝对线程安全
绝对的线程完全满足Brian Goetz给出的线程安全的定义, 这个定义其实是很严格的, 一个类要达到`不管运行时环境如何, 调用者都不需要任何额外的同步措施`通常需要付出很大的, 甚至有时候是不切实际的代价. 在Java API中标注自己是线程安全的类, 大多数都不是绝对的线程安全.

#### 相对线程安全
相对的线程安全就是我们通常意义上所讲的线程安全, 它需要保证对这个对象单独的操作是线程安全的, 我们在调用的时候不需要做额外的保障措施, 但是对于一些特定顺序的连续调用, 就可能需要在调用端使用额外的同步手段来保证调用的正确性. 在Java代码中, 大部分的线程安全类都属于这种类型.

#### 线程兼容
线程兼容是指对象本身并不是线程安全的, 但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全使用, 就是我们平常常说的一个类不是线程安全的.

#### 线程对立
线程对立是指调用端是否采取了同步措施, 都无法再多线程环境中并发使用的代码. 由于Java语言天生就具备多线程特性, 线程对立这种排斥多线程的代码是很少出现的, 而且通常都是有害的, 应当尽量避免. 如Thread类的suspend()和resume()方法, 如果有两个线程同时持有一个线程对象, 一个尝试去中断线程, 另一个尝试去恢复线程, 如果并发进行的话, 无论调用时是否进行了同步, 目标线程都是存在死锁风险的, 如果suspend()中断的线程就是即将要执行resume()的那个线程, 那就肯定是要发生死锁. 也正是这个原因, suspend()和resume()方法已经被JDK声明废弃(@Deprecated). 常见的线程对立操作还有System.setIn(), System.setOut()和System.runFinalizersOnExit()等.

### 线程安全的实现方法
接下来就是如何实现线程安全, 这和我们的代码编写有很大的关系, 但虚拟机提供的同步和锁机制也起到了很大的作用.

#### 互斥同步
`互斥同步(Mutual Exclusion & Synchronization)`是一种常见的并发正确性保障手段. 同步是指在多个线程并发访问共享数据时, 保证共享数据在同一个时刻只被一个线程使用. 而互斥是实现同步的一种手段, 临界区(Critical Section), 互斥量(Mutex)和信号量(Semaphore)都是主要的互斥实现方式. 因此, 在这4个字里面, 互斥是因, 同步是果; 互斥是方法, 同步是目的.

在Java中最基本的互斥同步手段就是Synchronized关键字, synchronized关键字经过编译之后, 会在同步块前后形成monitorenter和monitorexit这两个字节码指令, 这两个字节码指令都需要一个reference类型的参数来指明锁定和解锁的对象. 如果Java程序中synchronized明确制定了对象参数, 那就是这个对象的reference. 如果没有明确指定, 那就是根据synchronize修饰的是实例方法还是类方法, 去取对应的对象实例或Class对象作为锁对象.

根据虚拟机规范要求, 在执行monitorenter指令时, 首先要尝试获取对象的锁, 如果这个对象没被锁定, 或者当前线程已经拥有了这个对象的锁, 把锁的计数器加1, 相应的在执行monitorexit指令时会将锁的计数器减1, 当计数器为0时, 锁就被释放. 如果获取对象失败, 那当前线程就要堵塞等待, 直到对象锁别另一个线程释放为止.

Java的线程时映射到操作系统的原生线程之上的, 如果要堵塞或唤醒一个线程, 都需要操作系统来帮忙完成, 这就需要从用户态转换到核心态中, 因此状态转换需要耗费很多处理器时间. 对于代码简单的同步块, 状态转换消耗的时间可能比用户代码执行的时间还要长. 所以synchronize是Java语言中一个重量级(Heavyweight)操作, 有经验的程序员都会在确实必要的情况下才使用这种操作. 而虚拟机本身也做了一些优化, 比如在通知操作系统堵塞线程之前加入一段自旋等待过程, 避免频繁地切入到核心态之中.

除了synchronized之外, 我们还可以使用java.util.concurrent包中重入锁(ReentrantLock)来实现同步. 在基本用法上, ReentrantLock与synchronized很相似, 他们都具备一样的线程重入特性, 只是代码写法上有点区别, 一个表现为API层面的互斥锁(lock()和unlock()方法配合try/fannaly语句块来完成), 另一个表现为原生语法层面的互斥锁. 不过, 相比synchronized, ReentrantLock增加了一些高级功能:
+ 等待可中断: 是指当持有锁的线程长期不释放锁的时候, 正在等待的线程可以选择放弃等待, 改为处理一些别的事情, 可中断性对处理执行时间非常长的同步块很有帮助.
+ 公平锁: 是指多个线程在等待同一个锁的时候, 必须按照申请锁的时间先后顺序来依次获得锁. 而非公平锁不能保证这一点, 当锁释放的时候, 任何一个等待锁的线程都有可能获得锁. synchronized中是非公平锁, ReentrantLock默认情况下也是非公平的, 不过可以在构造的时候传递布尔值进行设置为公平锁.
+ 锁绑定多个条件: 是指一个ReentrantLock对象可以同时绑定多个Condition对象, 而synchronized中, 锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件, 如果要和多于一个条件关联的时候, 就不得不额外地添加一个锁, 而ReentrantLock则无须这么做, 只需要多次调用newCondition()方法即可.

如果要使用上述功能, 选用ReentrantLock是一个很好的选择. 然而在性能上进行比较的话, 如果部署的是在JDK1.5之前的版本, ReentrantLock具有较大的性能优势. 但是在JDK1.6及以后的版本, synchronized和ReentrantLock性能上的差距基本没有. 并且虚拟机在未来的性能改进中也会更加偏向于原生的synchronized, 所以还是提倡如果可以使用synchronized实现的话, 还是优先考虑使用synchronized进行同步.

#### 非阻塞同步
互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题, 因此这种同步也称为`阻塞同步(Blocking Synchronization)`. 从处理问题的角度来说, 互斥同步属于一种悲观的并发策略, 总是认为只要不去做正确的同步措施(如加锁), 那就肯定要出问题, 无论共享数据是否真的会出现竞争, 它都要进行加锁, 用户态核心态转换, 维护锁计数器和检查是否有阻塞的线程需要唤醒等操作.  随着硬件指令集的发展, 我们有了另外一个选择: 基于冲突的乐观并发策略, 通俗来说, 就是先进行操作, 如果没有其他线程争用共享数据, 那操作就成功了. 如果有共享数据争用, 产生了冲突, 那就再采用补救措施(最常见的就是不断地重试, 直到成功为止), 这种乐观的并发策略的许多实现都不需要把线程挂起, 因此这种同步操作称为`非堵塞同步(Non-Blocking Synchronization)`.

`非堵塞同步`是需要`硬件指令集的发展`才能进行的: 我们需要操作和冲突检测这两个步骤具备原子性. 如果这里再使用互斥同步来保证就失去了意义, 所以我们只能靠硬件来完成这件事. 硬件保证一个从语义上看起来需要多次操作的行为只通过一条处理器指令就能完成:
+ 测试并设置(Test-and-Set)
+ 获取并增加(Fetch-and-Increment)
+ 交换(Swap)
+ 比较并交换(Compare-and-Swap, 下称CAS)
+ 加载链接/条件存储(Load-Linked/Store-Conditional, 下称LL/SC)

CAS指令需要3个操作数, 分别是内存位置(在Java中可以简单理解为变量的内存地址, 用V表示), 旧的预期值(用A表示)和新值(用B表示). CAS指令执行时, 当且仅当V符合旧的预期值时, 处理器才用新值B更新V的值, 否则它就不会执行更新, 但是无论是否更新了V的值, 都会返回V的旧值. 上述的处理过程就是一个原子操作.

在JDK1.5之后, Java程序才可以通过CAS操作, 该操作由sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供, 虚拟机在内部对这些方法做了特殊处理, 即时编译出的结果就是一条平台相关的处理器CAS指令, 没有方法调用的过程, 或者可以认为是无条件内联进去了.
>这种被虚拟机特殊处理的方法称为固有函数(Intrinsics), 类似的固有函数还有Math.sin()等.

由于Unsafe类不是提供给用户程序调用的类(Unsafe.getUnsafe()的代码中限制了只有启动类加载器(Bootstrap ClassLoader)加载的Class才能访问它), 因此, 如果不采用反射手段, 我们只能通过其他Java API来间接使用它, 如J.U.C包中的整数原子类, 其中的compareAndSet()和getAndIncrement()等方法都使用了Unsafe类的CAS操作.

```java
public class AtomicTest {

    public static AtomicInteger race =  new AtomicInteger(0);

    public static void increase() {
        race.incrementAndGet();
    }

    private static final int THREADS_COUNT = 20;

    public static void main(String[] args) throws Exception{
        Thread[] threads = new Thread[THREADS_COUNT];
        for (int i = 0; i < THREADS_COUNT; i++) {
            threads[i] = new Thread(new Runnable() {
                @Override
                public void run() {
                    for (int i = 0; i < 10000; i++) {
                        increase();
                    }
                }
            });
            threads[i].start();
        }

        while (Thread.activeCount() > 2) {
            Thread.yield();
        }

        System.out.println(race); //200000
    }
}


//incrementAndGet()方法源码,JDK1.7
public final int increment() {
	for(;;){
    	int current = get();
        int next = current + 1;
        if (compareAndSet(current, next)) {
        	return next;
        }
    }
}
```

虽然CAS看起来很完美, 但是也存在一个缺陷. 假设一个值初始化在内存中的值为A, 这时候一个耗时较长的线程T1读取的A, 由于内部操作耗时, 需要等待一段时间. 这时候一个耗时较短的线程T2读取了A, 然后修改该值为B, 并提交上去了. 这时候内存的值为B, 这时候又有一个耗时较短线程T3, 读取了B, 然后修改了该值为A, 并提交成功了. 这时候内存的值为A了, 这时候线程T1完成了操作, 它进行提交的时候, 对比了一下内存的值和旧的预期值, 发现都是A, 于是提交了修改结果, 并成功了. 但是线程T1并不应该成功提交该次结果, 因为这时候的A并不是原来的版本的A. 这就是常见的`ABA`问题. 为了解决这个问题, J.U.C包中提供了一个带标记的原子引用类`AtomicStampedReference`用于版本识别. 但是一般情况下ABA问题不会影响程序并发的结果, 如果要解决ABA的问题, 改用传统的互斥同步可能会更加高效.

#### 无同步方案
如果要保证线程安全, 并不是一定要进行同步, 两者没有必然的因果关系. 同步只是保证共享数据争用时的正确性的手段, 如果一个方法本身就不涉及共享数据, 那它自然就无须任何同步措施去保证正确性, 因此一些代码天生就是线程安全的.

可重入代码(Reentrant Code): 亦称纯代码(Pure Code), 可以在代码执行的任何时刻中断它, 转而执行另外一段代码(包括递归调用自身), 而在控制权返回后, 原来的程序不会出现任何错误. 也就是我们常说的`函数式代码`. 只要满足可重入代码的特征, 就一定是线程安全的. 但是线程安全的并不全是可重入代码. 可重入代码具有一些基本特征: 不依赖存储在堆上数据和公用的系统资源, 用到的状态量都由参数传入, 或者不可变变量, 不调用非可重入的方法等等. 这里有一个简单的原则来判断代码是否具备可重入性: 如果一个方法, 它的返回结果是可以预测的, 只要输入了相同的数据, 都能返回相同的结果, 那它就满足可重入性的要求, 当然也就是线程安全的.
> 大多数的数学函数都是可重入代码.

线程本地存储(Thread Local Storage): 如果一段代码所需要的数据必须与其他代码共享, 那就看看这些共享数据是否保证在同一线程中执行? 如果保证, 我们就可以把共享数据的可见性范围限制在一个线程之内, 这样, 无须同步也能保证线程之间不出现数据争用的问题.

符合这种特点的应用并不少见, 大部分使用消费队列的架构模式(如`生产者-消费者`模式)都会将产品的消费过程尽量在一个线程中消费完, 最重要的一个应用实例就是经典的Web交互模型中的`一个请求对应一个服务器线程(Thread-per-Request)`的处理方式, 这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程安全的问题.

Java语言中, 如果一个变量要被多线程访问, 可以使用volatile关键字声明它为`易变的`. 如果一个变量要被某个线程独享, 可以通过java.lang.ThreadLocal类来实现线程本地存储的功能. 每一个线程的Thead对象都有一个TheadLocalMap对象, 这个对象存储了一组以ThreadLocal.threadLocalHashCode为键, 以本地变量为值的K-V值对, ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口, 每一个ThreadLocal对象都包含了一个独一无二的threadLocalHashCode值, 使用这个值可以在线程K-V键值对中找回对应的本地线程变量.

## 锁优化
高效并发是从JDK1.5到JDK1.6的一个重要改进, HotSpot虚拟机开发团队在这个版本上花费了大量的精力去实现各种锁优化技术, 如适应性自旋(Adaptive Spining), 锁消除(Lock Elimination), 锁粗化(Lock Coarsening), 轻量级锁(Lightweight Locking)和偏向锁(Biased Locking)等. 这些技术都是为了在线程之间更加高效地共享数据, 以及解决竞争问题, 从而提高程序的执行效率.

### 自旋锁与自适应自旋
就像前面提到的, 互斥同步对性能最大的影响就是阻塞的实现, 挂起线程和恢复线程的操作都需要转入内核态中完成, 这些操作给系统的并发性能带来了很大的压力. 同时虚拟机的开发团队发现在许多应用中, 共享数据的锁定状态只会持续很短时间, 为了这段时间去挂起和恢复线程并不值得. 如果物理机器有多个处理器, 可以让两个及以上的线程同时并行执行, 我们可以让后面请求锁的那个线程`稍等一下`, 但不放弃处理器的执行时间, 看看持有锁的线程是否很快就会释放锁. 为了让线程等待, 我们只需让线程执行一个忙循环(自旋), 这项技术就是所谓的自旋锁.

自旋锁在JDK1.4.2中就已经引入, 只不过默认是关闭的, 可以使用-XX:+UseSpining参数来开启, 在JDK1.6中就已经改为默认开启了. 自旋等待不能替代阻塞, 且不说对处理器数量的要求, 自旋等待本身虽然避免了线程切换的开销, 但是它需要占用处理器的时间. 因此如果锁占用的时间很短, 自旋等待的效果自然很好. 反之, 如果锁被占用的时间很长, 那么自旋的线程只会白白消耗处理器资源, 而不做任何有用的工作, 反而会带来性能上的浪费. 因此, 自旋锁等待的时间必须有一个限定, 如果自旋锁超过了默认的次数还没有成功获得锁, 就应当使用传统的方式去挂起线程. 自旋次数的默认值是10次, 用户可以通过设置参数:-XX:PreBlockSpin来进行设置.

在JDK1.6中引入了自适应的自旋锁. 自适应意味着自旋的时间不再固定, 而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定. 如果同一个锁对象上, 自旋等待刚刚成功获得过锁, 并且持有锁的线程正在运行, 那么虚拟机就会认为这次自旋是很有可能成功的, 进而它将运行自旋等待持续相对更长的时间, 如100个循环. 另外, 如果对于某个锁, 自旋很少成功过, 那在以后要获取这个锁时就可能省略掉自旋过程以避免浪费处理器资源, 随着程序的运行和性能监控信息的不断完善, 虚拟机对程序锁的状况预测也会越来越准确, 虚拟机也会变得越来越`聪明`.

### 锁消除
锁消除是指在虚拟机即时编译器在运行时, 对一些代码上要求同步, 但是检测到不可能存在共享数据竞争的锁进行消除. 锁消除的主要判定依据是来源于逃逸分析的数据支持, 如果判断在一段代码中, 堆上的所有数据都不会逃逸出去从而被其他线程访问到, 那就可以把它们当做栈上数据对待, 认为它们是线程私有的, 同步加锁过程自然就没有必要了.

也许很多人就会有疑问, 在明知道数据不存在争用的时候, 程序员干嘛要添加同步块? 答案是由许多同步措施不是程序员自己加入的, 同步的代码在Java程序中的普遍程度也许超出了大部分读者的想象.

```java
public String concatString(String s1, String s2, String s3) {
	return s1 + s2 + s3;
}
```

我们知道String是一个不可变的类, 对字符串的连接操作总是通过生成新的对象来进行的, 因此Javac编译器会对String连接做自动优化. 在JDK1.5之前的版本, 会转换为StringBuffer对象的append()操作, 在JDK1.5之后的版本, 会转换为StringBuilder对象的连续append()操作.

```java
public String concatString(String s1, String s2, String s3) {
	StringBuffer sb = new StringBuffer();
    sb.append(s1);
    sb.append(s2);
    sb.append(s3);
    return sb.toString();
}
```

而StringBuffer中的append方法包含了一个同步块, 锁就是sb对象. 虚拟机观察变量sb, 很快就会发现它的动态作用域被限定在concatString()方法内部, 也就是说, sb的所有引用永远不会逃逸出concatString()方法之外, 其他线程无法访问到它. 因此, 虽然这里有锁, 但是可以被安全地消除掉.

### 锁粗化
原则上, 我们编写代码的时候, 总是推荐将同步块的作用范围限制得尽量小, 只在共享数据的实际作用域中才进行同步, 这是为了使得需要同步操作的操作数量尽可能变小, 如果存在锁竞争, 那就等待锁的线程也可以尽快拿到锁.

大部分情况下, 以上原则是正确的. 但是如果一系列的连续操作都对同一个对象反复加锁和解锁, 甚至加锁操作是出现在循环体中的, 那即使没有线程竞争, 频繁地进行互斥同步操作也会导致不必要的性能损耗. 就像上面的例子: 连续使用append()方法, 如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁, 将会把锁加锁同步的方位扩大(粗化)到整个操作序列的外部, 就是全部的append操作, 这样就只需要加锁一次即可了.

### 轻量级锁
轻量级锁是JDK1.6之前加入的新型锁机制, 它的名字中的`轻量级`是相对于操作系统互斥量来实现的传统锁而言的, 因此传统的锁机制就称为`重量级`锁. 首先需要强调的一点是: 轻量级锁并不是用来代替重量级锁的, 它的本意是在没有多线程竞争的前提下, 减少传统的重量级锁使用系统互斥量产生的性能消耗.

HotSpot虚拟机的对象头(Object Header)分为两部分信息, 第一部分存储对象运行时数据, 如哈希码(HashCode), GC分代年龄(Generational GC Age)等, 这部分数据长度在32位和64位虚拟机中分别是32bit和64bit. 官方称为`Mark World`, 是实现轻量级锁的关键. 另外一部分用于存储指向方法区对象类型数据的指针, 如果是数组对象的话, 还会有一个额外的部分用于存储数组长度.

由于对象头信息是与对象自身定义的数据无关的额外存储成本, 考虑到虚拟机的空间效率, Mark World被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息, 它会根据对象的状态复用自己的存储空间. 如: 在32位的HotSpot虚拟机中对象未被锁定的状态下, 32bit空间中25bit用于存储对象的哈希码(HashCode), 4bit用于存储对象分代年龄, 2bit用于存储锁标记位, 1bit固定为0.

![show](https://image.cjyong.com/blog/jvm/13.jpg)

我们回到轻量级锁的执行过程中. 在代码进入到同步块的时候, 如果此同步对象没有被锁定(所标记为01), 虚拟机首先将在当前线程的栈帧中建立一个名为`锁记录(Lock Record)`的空间, 用于存储锁对象目前的Mark Word拷贝(官方称, Displaced Mark Word).

然后虚拟机将使用CAS操作尝试将对象的Mark World更新为指向Lock Record的指针. 如果更新成功了, 那么这个线程就拥有了该对象的锁, 并且对象Mark Word的锁标记位变为`00`, 即表示对象处于轻量级锁定状态.

![show](https://image.cjyong.com/blog/jvm/14.jpg)

![show](https://image.cjyong.com/blog/jvm/15.jpg)

如果更新操作失败, 虚拟机首先会检查对象的Mark World是否指向当前栈帧, 如果是说明当前线程拥有了这个对象的锁, 那么就可以直接进入同步块里执行. 否则说明这个锁对象已经被其他线程抢占了, 如果有两条以上的线程争用同一个锁, 那轻量级锁就不在有效, 要膨胀为重量级锁, 锁标记就要变为`10`, Mark Word中存储的就是指向重量级锁(互斥量)的指针, 后面等待锁的线程也要进入堵塞状态.

解锁过程也是同样通过CAS操作来进行, 如果对象MarkWord仍然是指向当前线程的锁记录, 那就使用CAS操作把当前的Mark World和线程中复制的Displaced Mark World替换回来, 如果替换成功, 同步过程完成. 如果替换失败, 说明有其他线程尝试获取该锁, 那就要在释放锁的同时, 唤醒挂起的线程. 

轻量级锁可以提升同步性能的依据是`对于绝大部分的锁, 在同步期间内都是不存在竞争的`. 如果没有竞争, 轻量级锁使用CAS操作避免了使用互斥量的开销, 如果存在锁竞争, 除了互斥量的开销, 还额外进行了CAS操作, 因此在有竞争的情况下, 轻量级锁比传统的重量级锁更慢.

### 偏向锁
偏向锁的目的是消除数据在无竞争情况下的同步, 进一步提高程序的运行性能. 如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量, 那偏向锁就是在无竞争的情况下把整个同步都消除掉, 连CAS操作都不进行.

当锁对象第一次被线程获取的时候, 虚拟机将会把对象头中的标记位设为`01`, 同时使用CAS操作把获取这个锁的线程ID记录在对象的Mark Word之中, 如果CAS操作成功, 持有偏向锁的线程以后每次进入该同步块都不需要进行任何同步操作.

当另外有线程尝试获取这个锁的时候, 偏向模式就宣告结束, 根据锁对象是否处于被锁定状态, 撤销偏向(Revoke Bias)后恢复到未锁定(标记位为`01`)或轻量级锁定(`00`), 后续的同步操作就像上面介绍的轻量级锁那样执行.

偏向锁可以提高带有同步但是没有竞争的程序性能, 它同样带来了效益权衡(Trade-Off). 也就是它不一定对程序有益, 如果程序大多数的锁总是被不同的线程访问, 那偏向锁就是多余的. 有时候使用参数-XX:-UseBiasedLocking来禁止偏向锁优化反而可以提升性能.









