# Java 内存模型和线程

## 概述

多任务处理在现代计算机操作系统中几乎已是一项必备的功能, 在许多情况下, 让计算机同时去做几件事, 不仅是因为计算机的运算能力太强了, 而是计算机的运行速度和它的存储和通信子系统速度的差距太大, 大量的时间浪费在磁盘 IO, 网络通信或者数据库访问上了. 为了提高处理器的处理效率, 而不是把时间浪费在等待上, 同时让计算机同时处理多项任务是最容易想到, 也被证明是非常有效的手段.

除了充分利用计算机处理器的能力外, 一个服务端同时对多个客户端提供服务则是另一个更加具体的并发应用场景. 衡量一个服务性能的高低好坏, 每秒事务处理数(Transactions Per Second, TPS)是最重要的指标之一, 它代表着一秒内服务端平均可以响应的请求总数, 而 TPS 值又与程序的并发能力有着紧密的关系. 如果对于计算量相同的任务, 程序线程并发协调得越有条不紊, 效率自然就越高. 反之, 线程之间频繁阻塞甚至死锁, 将会大大降低程序的并发能力.

## 硬件的效率与一致性

`让计算机并发执行若干个运算任务`与`更充分地利用计算机处理器的效能`之间的因果关系, 看起来顺理成章, 实际上它们的关系远远没有想象中的那么简单, 其中一个重要的复杂性来源就是绝大多数的运算任务都不可能只靠处理器`计算`完成, 处理器至少要与内存交互, 如读取运算结果, 存储运算结果等待, 这个 IO 操作时很难消除的. 由于计算机的存储设备与处理器的运算速度有好几个数量级的差距, 所以现代的计算机系统不得不添加一层读写速度尽可能接近处理器运算速度的高速缓存(Cache)来作为内存与处理器之间的缓冲: 将计算所需要的数据先复制到缓存中, 让运算可以快速进行, 当运算结束的时候在从缓存中同步到内存中, 这样处理器就不用等待缓慢的内存读写了.

添加高速缓存的存储交互很好地解决了处理器与内存的速度矛盾, 但是也为计算机系统带来更高的复杂度, 因为它引入了一个新的问题: 缓存一致性(Cache Coherence). 在多处理器系统中, 当多个处理器的运算任务都涉及到同一块主内存区域时, 就有可能导致各自的缓存数据不一致, 如果发生了这种情况, 那么同步到主内存的数据应该以谁的缓存数据为准呢? 为了解决一致性的问题, 需要各个处理器遵循一些协议, 在读写时需要按照协议来进行操作, 这类协议有: MSI, MESI(Illinois Protocol), MOSI, Synapse, Firefly 及 Dragon Protocol 等等.

![show](https://image.cjyong.com/blog/jvm/8.jpg)

除了增加高速缓存之外, 为了使得处理器内部的运算单元可以尽量的被充分使用, 处理器可能对输入代码进行乱序执行(Out-Of-Order Execution)优化, 处理器会在计算之后将乱序执行的结果进行重组, 保证该结果与顺序计算的结果一致, 但不保证程序中各个语句的计算先后次序与输入代码时一致. 因此如果一个计算任务依赖另一个计算任务, 其顺序性不能简单地靠代码的先后顺序来保证. Java 虚拟机中的即时编译器也有类似的指令重排序优化(Instruction Reorder).

## Java 内存模型

Java 虚拟机规范中试图定义一种 Java 内存模型(Java Memory Model, JMM)来屏蔽掉各种硬件和操作系统上的差异, 以实现让 Jav 程序在各种平台下都可以达到一致的访问效果. 在此之前, 主流的程序语言(C/C++)都是直接使用物理硬件和操作系统的内存模型, 常常因为硬件上的差异, 导致程序内存访问的出错, 而必须针对性的编程.

定义 Java 内存模型并不是一件容易的事, 这个模型必须定义的足够严谨, 才能让 Java 的并发内存访问操作不会产生歧义. 但是也必须足够宽松, 使得虚拟机的实现有足够的自由空间来利用硬件的各种特性(寄存器, 高速缓存和指令集里特殊的指令)来获取更好的执行速度.

### 主内存和工作内存

Java 内存模型的主要目标是定义程序中各个变量的访问规则, 即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节. 这里的变量与 Java 编程中的变量有所区别, 如它包括了实例字段, 静态字段和数组对象的元素, 但不包括局部变量与方法参数, 因为后者是线程私有的, 不会被共享, 自然也就不存在竞争的问题. 为了获得较好的执行性能, Java 内存模型没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存交互, 也没有限制即时编译器进行调整代码的执行顺序这类的优化措施.

Java 内存模型规定所有的变量都存储在主内存(Main Memory)中(类似物理硬件中的主内存). 每条线程都还有自己的工作内存(Working Memory)(类似高速缓存), 线程的工作内存中保存了该线程中使用到的变量的主内存副本拷贝, 线程对变量的所有操作都必须在工作内存中进行, 而不能直接读写主内存中的变量. 不同线程之间也无法直接访问对方工作内存中的变量, 线程间的变量值传递均需要通过主内存来完成. 三者之间的关系:

![show](https://image.cjyong.com/blog/jvm/9.jpg)

### 内存间交互操作

主内存与工作内存之间的具体协议: 一个变量如何从主内存拷贝到工作内存, 如何从工作内存同步回主内存子类的实现细节. Java 内存模型中定义了以下 8 种操作来完成, 虚拟机必须保证下面 8 中操作都是原子的, 不可再分的(double 和 long 类型有些操作例外).

- lock(锁定): 作用于主内存的变量, 它把一个变量标识为一条线程独占的状态.
- unlock(解锁): 作用于主内存的变量, 它把一个变量从锁定状态释放出来, 只有释放的变量才可以被其他线程锁定.
- read(读取): 作用于主内存的变量, 它将一个变量的值从主内存传输到线程的工作内存中, 以便随后的 load 动作使用.
- load(载入): 作用于工作内存的变量, 它把 read 操作从主内存中得到的变量放入工作内存的变量副本之中,
- use(使用): 作用于工作内存的变量, 它把工作内存中的一个变量的值传递给执行引擎, 每当虚拟机遇到一个需要使用到变量的值的字节码指令时, 才会执行这个操作.
- assigin(赋值): 作用于工作内存的变量, 它把一个从执行引擎接受到的值赋给工作内存的变量, 每当虚拟机遇到一个给变量赋值的字节码指令时才执行这个操作.
- store(存储): 作用于工作内存的变量, 它把工作内存中一个变量的值传送到主内存中, 以便随后的 wirte 操作使用.
- write(写入): 作用于主内存的变量, 它把 store 操作从工作内存中得到的变量值放入到主内存的变量中.

所以如果要把一个变量从主内存复制到工作内存, 那就需要顺序地执行 read 和 load 操作, 如果从工作内存同步到主内存, 就需要顺序执行 store 和 write 操作. 注意, Java 内存模型只要求上述两个操作必须按顺序执行, 没有要求是连续的. 也就是说, read 和 load 之间, store 和 write 之间是可以插入其他指令的. 如对主存中的变量 a, b 进行访问时, 一种可能出现的顺序是:read a, read b, load b, load a. 除此之外, Java 内存模型还规定了执行上述 8 种操作必须满足以下要求:

- 不允许 read 和 load, store 和 write 操作之一单独出现, 即不允许一个变量从主内存读取了但工作内存不接受, 或者从工作内存发起回写但主内存不接受的情况出现.
- 不允许一个线程丢弃它的最近的 assign 操作, 即变量在工作内存中改变了之后必须把该变化同步回主内存.
- 不允许一个线程无原因地(没发生 assign 操作)把数据从线程工作内存同步到主内存.
- 一个新的变量只能在主内存中`诞生`, 不允许在工作内存中直接使用一个未被初始化(load 或 assign)的变量, 换句话说, 就是对一个变量实施 use, store 操作之前, 必须执行过了 assign 和 load 操作.
- 一个变量在同一时刻只允许一条线程对其进行 lock 操作, 但 lock 操作可以被同一条线程重复执行多次, 多次 lock 之后只能执行相同次数的 unlock 操作, 变量才会被解锁.
- 如果对一个变量执行 lock 操作, 那将会清空工作内存中此变量的值, 在执行引擎使用这个变量前, 需要重新执行 load 或 assign 操作初始化变量的值.
- 如果一个变量没有被 lock 操作锁定, 那就不允许对它执行 unlock 操作, 也不允许 unlock 一个被其他线程锁定的变量.
- 对一个变量执行 unlock 操作之前, 必须将此变量同步回主内存中(执行 store, write 操作).

### volatile 型变量的特殊规则

volatile 可以说是 Java 虚拟机提供的最轻量级的同步机制, 但是它并不容易完全被正确, 完整地理解. 当一个变量被定义为了 volatile 之后, 它将具有两种特性: 保证此变量对于其他线程的可见性; 禁止指令重排序优化.

保证此变量对于其他线程的可见性, 即当一条线程修改了这个变量的值, 这个新值对于其他线程来说是可以立即得知的. 对于一般的普通变量在线程间的传递都需要通过主内存来完成, 线程 A 读取并修改了该变量, 线程 B 只有在线程 A 写入之后, 重新读取主内存中的值, 这个新的变量值才会对线程 B 可见.

由于可见性的保障, 很多开发人员可能产生误解: volatile 变量对所有的线程时立即可见的, 对于 volatile 变量的 write 操作都可以立即反应到其他线程中, 换句话说, volatile 变量在各个线程中是一致的, 所以基于 volatile 变量的运算在并发条件下是安全的. 前半部分的论据是正确的, 但是不能保证对 volatile 变量的运算在并发条件下也是安全的, 因为 Java 里面的运算并不是原子操作, 导致 volatile 变量的运算在并发条件下也是不安全的.

```java
public class VolatileTest {

    public static volatile int race = 0;

    public static void increase() {
        race++;
    }

    private static final int THREADS_COUNT = 20;

    public static void main(String[] args) {
        Thread[] threads = new Thread[THREADS_COUNT];
        for (int i = 0; i < THREADS_COUNT; i++) {
            threads[i] = new Thread(new Runnable() {
                @Override
                public void run() {
                    for (int i = 0; i < 1000; i++) {
                        increase();
                    }
                }
            });
            threads[i].start();
        }

        while (Thread.activeCount() > 2) { //这里在IDEA下运行, IDEA会添加一个守护线程, 所以为2, 如果单纯JDK编译运行(javac, java)设为1即可.
            Thread.yield();
        }
        System.out.println(race); //19745
    }
}
```

这里我们可以很诧异的发现 race 的值没有一次是等于 20000 的, 问题出现在哪里? 问题就出现在这个 race++操作上了, 我们对 class 文件进行反编译一下可以得到:

```java
...
public static void increase();
descriptor: ()V
flags: ACC_PUBLIC, ACC_STATIC
Code:
  stack=2, locals=0, args_size=0
     0: getstatic     #2                  // Field race:I
     3: iconst_1
     4: iadd
     5: putstatic     #2                  // Field race:I
     8: return
  LineNumberTable:
    line 15: 0
    line 16: 8
...
```

increase 函数主要的指令有四个: `getstatic, iconst_1, iadd, putstatic`. 当我们使用`getstatic`时, volatile 指令保证了这个时候 race 的值的准确性. 但是当线程执行后面的指令`iconst_1, iadd, putstatic`等操作的时候, 其他线程可能修改了 race 的值, 那这时候线程操作的值就过时了, 最后我们将过时的值(较小)的同步回了主内存. 这就导致最终输出的值变小了. 使用字节码来分析问题还是不够严谨, 真正要认真查看问题, 应该使用-XX:+PrintAssembly 参数输出反汇编来分析指令, 更加可靠.

所以 volatile 变量只能保证可见性, 使用 volatile 变量需要满足以下两个要求:

- 运算结果不依赖变量的当前值, 或者能够确保只有单一线程修改变量的值.
- 变量不需要与其他的状态变量共同参与不变约束.

如:

```java
volatile boolean shutdownRequested;

public void shutdown() {
    shutdownRequested = true;
}

public void doWork() {
    while(shutdownRequested) {
        //Do something
    }
}
```

这种情况下就适合利用 volatile 变量来控制并发, 当 shutdown()函数调用时, 可以保证所有线程中执行的 doWork()方法都立即停止下来. 对于其他不满足条件的情况, 还是需要通过加锁(sychronized 或者 java.util.concurrent 中的原子类)来保证原子性.

volatile 变量的第二个语义是禁止指令重排序, 普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果, 而不能保证变量赋值的操作顺序与程序代码的执行顺序一致. 在一个线程的方法执行过程中没办法感知到这一点, 也就是所谓的`线程内表现为串行的语义(Within-Thread As-If-Serial Semantics)`.

```java
Map configOptions;
char[] configText;
volatile boolean initialized = false;

//假设以下代码在线程A中执行
//线程A的主要任务是读取配置信息, 然后设置初始化为true以通知其他线程配置可用
configOptions = new HashMap();
configText = readConfigFile(fileName);
processConfigOptions(configText, configOptions);
initialized = true;

//假设一下代码在线程B中执行
while(!initialized) {
   sleep();
}
doSomethingWithConfig();
```

如果 initalized 变量没有设置 volatile, 就可能导致指令重排序的优化, 导致线程 A 中最后一句代码`initialized = true`被提前执行, 这样线程 B 中使用配置信息的代码就会出错. 使用 volatile 就可以避免这种情况的发生.

这里在以 DCL 单例模式的例子, 再次讲解指令重拍的原理:

```java
public class Singleton {

   private volatile static Singleton instance;

    public static Singleton getInstance() {
       if (instance == null) {
           synchronized(Singleton.class) {
               if (instance == null) {
                   instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

编译之后, 这段代码对 instance 变量赋值部分:

```C
...
mov $0x3375cdb0, %esi
mov $eax, 0x150(%esi) //赋值操作, 给instance赋值
shr $0x9, %esi
movb $0x0, 0x1104800(%esi)
lock addl $0x0, (%esp) //添加volatile修饰之后, 新增的
...
```

我们可以发现, 我们添加了 volatile 关键字之后, 新增加了一句: `lock add1 $0x0 (%esp)`, 将 ESP 寄存器的值加 0, 这显然是一个空操作, 关键在于前面添加了`lock`前缀, 查询 IA32 手册, 它的作用是使得本 CPU 的 Cache 写入内存, 该写入动作会引起别的 CPU 或别的内核无效化(Invalidate)其 Cache, 这种操作相当于对其它 Cache 中的变量做了一次`store`和`write`操作. 通过这个空操作, 是的 volatile 变量的修改对其它 CPU 立即可见. 同时这个操作也相当于一个内存屏障(Memory Barrier), 重排序时不能把后面的指令重排序到内存屏障之前的位置.

从硬件架构上来说, 指令重排是指 CPU 采用了允许将多条指令不按程序规定的顺序分开送给各相应电路单元处理. 但并不是指令任意重排, CPU 需要能正常处理指令依赖情况以保证程序可以得到正确的结果. 如: 指令 1 把地址 A 中的值加 10, 指令 2 将地址 A 中的值乘以 2, 指令 3 将 B 中地址减去 3. 指令 1 和 2 是相互依赖的, 它们之间的顺序不能重排, 指令 3 则可以重排到指令 1,2 之间或之前, 只要保证 CPU 执行到后面依赖 A,B 的值的时候, 可以得到正确的值.

volatile 指令在大多数的情况下的性能是优于锁的, 但是我们很难量化这种性能上的优化. 另外, volatile 本身在读取上的消耗是和普通变量没有多少差异的, 但是在写操作上则是复杂了一些, 因为需要在代码中插入许多内存屏障指令来保证处理器不发生乱序执行.

最后看一下 Java 内存模型中对 volatile 变量定义的特殊规则. 假如 T 表示一个线程, V 和 W 分别表示两个 volatile 变量, 那么在进行 read, load, use, assign, store 和 write 操作时, 需要满足以下要求:

- 只有当线程 T 对变量 V 执行的前一个动作是 load 的时候, 线程 T 才能对变量 V 执行 use 动作(每次使用之前都必须 read, load, 起到刷新的作用). 并且, 只有当线程 T 对变量 V 执行的后一个动作是 use 的时候, 线程 T 才能对变量 V 执行 load 动作. 即 read, load, use 必须在一起调用, 保证每次使用前都是从主存中获取最新的值.
- 只有当线程 T 对变量 V 执行的最后一个动作是 assign 的时候, 线程 T 才能对变量 V 执行 store 操作. 并且, 只有当线程 T 对变量 V 执行的后一个操作时 store 的时候, 线程 T 才能对变量 V 执行 assign 操作. 即: assign, store, write 三个指令必须连续一起出现, 保证了每次修改都能立马更新到主存之间.
- 假定动作 A 是线程 T 对变量 V 实施的 use 或 assign 动作, 假定动作 F 是和动作 A 相关联的 load 或 store 动作, 假定动作 P 是和动作 F 相对应的对变量 V 的 read 或 write 动作. 类似的, 假定动作 B 是线程 T 对变量 W 实施的 use 或 assign 动作, 假定动作 G 是和动作 B 相关联的 load 或 store 动作, 假定动作 Q 是和动作 G 相对应的对变量 W 的 read 或 write 动作. 如果 A 先于 B, 那么 P 限于 Q.(即保证 volatile 修饰的变量,不会被指令重排序优化, 与代码的执行顺序一样).

### 对于 long 和 double 型变量的特殊规则

Java 内存模型要求 lock, unlock, read, load, assign, use, store, write 这 8 个操作都具有原子性, 但是对于 64 位的数据类型(long 和 double), 在模型中特别定义了一条相对宽松的固定: 允许虚拟机将没有被 volatile 修饰的 64 位数据类型的读写操作划分为两次 32 位的操作来进行, 即允许虚拟机实现选择可以不保证 64 位数据类型的 load, store, read 和 write 的原子性. 这就是所谓的 long 和 double 的`非原子协定(Nonatomic Treatment of double and long Variables)`.

如果多个线程共享一个并未声明 volatile 的 long 或者 double 类型变量, 并同时对它们进行读取和修改操作, 某些线程可能读取到了一个即非原值, 也不是其他线程修改的值代表了`半个变量`的数值. 这种情况非常罕见(在商用 Java 虚拟机中不会出现), 因为 Java 内存模型虽然允许虚拟机不把 long 和 double 变量的读写实现成原子操作, 但允许虚拟机选择把这些操作实现为原子性操作, 并且`强烈建议`虚拟机这样做. 目前大多数的商用虚拟机都选择把 64 位数据的读写操作作为原子操作来对待, 因此我们编写代码的时候就不要把 long 和 double 变量专门声明为 volatile.

### 原子性, 可见性与有序性

`原子性(Atomicity)` : 由 Java 内存模型来直接保证原子性变量操作包括: read, load, assign, use, store 和 write. 如果需要更大范围的原子性保证, Java 内存模型提供了 lock 和 unlock 操作来保证, 尽管虚拟机并未把 lock 和 unlock 操作直接开发给用户使用, 但是却提供了更高层次的字节码指令 monitorenter 和 monitorexit 来隐式地使用这两个操作, 这两个字节码反应在 Java 代码块中就是 synchronize 关键字. 因此在 synchronize 块中的操作也具备原子性.

`可见性(Visibility)`: 可见性是指当一个线程修改了共享变量的值, 其他线程可以立即得知这个修改. volatile 变量的使用中我们详细讨论了这一点. Java 内存模型是通过在变量修改后将新值同步回主内存, 在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性. volatile 的特殊规则保证了新值可以立即同步到主内存 以及每次使用前立即从主内存刷新, 保证了多线程操作时变量的可见性. 除了 volatile 之外, 还有 synchronize 和 final 可以实现可见性. synchronize 可见性是由`对一个变量执行unlock之前, 必须把此变量同步回主内存中(执行store, write操作)`这条规则获得的. 而 final 关键字的可见性是指: 被 final 修饰的字段在构造器中一旦初始化完成, 并且构造器没有把 this 引用传递出去, 那在其他线程中就能看见 final 字段的值.

`有序性(Ordering)`: Java 内存模型的有序性在前面也详细讲解过. Java 程序中天然的有序性可以总结为一句话: 如果在本线程中观察, 所有的操作都是有序的; 如果在一个线程中观察另一个线程, 所有的操作都是无序的. 前半句是指`线程内表现为串行的语义(Within-Thread As-If-Serial Semantics)`, 后半句是指`指令重排序`现象和`工作内存与主内存同步延迟`现象. Java 语言提供了 volatile 和 synchronize 两个关键字来保证线程之间操作的有序性, volatile 本身就包含了禁止指令重排序的语义, 而 synchronize 则是由`一个变量在同一个时刻只允许一条线程对其进行lock操作`获得的, 这条规则决定了持有同一个锁的两个同步块只能串行进入.

### 先行发生原则

如果 Java 内存模型中所有的有序性都仅仅靠 volatile 和 synchronize 来完成, 那么有一些操作就会变得很繁琐, 但是我们在编写并发代码的时候并没有察觉. 这是因为 Java 语言中有一个`先行发生(happens-before)`的原则. 这个原则非常重要, 它是判断数据是否存在竞争, 线程是否安全的主要依据.

`先行发生`原则指的是什么? 先行发生是 Java 内存模型中定义的两项操作之间的偏序关系, 如果说操作 A 先行发生于操作 B, 其实就是说在发生操作 B 之前, 操作 A 产生的影响可以被操作 B 观察到. `影响`包括了修改内存中共享变量的值, 发送了消息, 调用了方法等等.

```java
//线程A中执行
i = 1;

//线程B中执行
j = i;

//线程C中执行
i = 2;
```

如果线程 A 先行发生于线程 B 操作, 暂时不考虑 C 操作, 那么可以确定的是在 B 操作之后, 变量 j 的值一定等于 1. 这是因为先行发生原则, `i = 1`的结果可以被观察到. 现在再来考虑线程 C, 我们依然保持线程 A 和线程 B 之间的先行关系, 而线程 C 出现在线程 A 和线程 B 操作之间, 但是 C 和 B 没有先行关系, 那么 j 的值又会是多少呢? 答案是不确定的. 因为 C 对变量的影响有可能被线程 B 观察到, 也有可能不会被观察到, 这时候线程 B 就存在读取过期数据的可能, 不具备多线程安全性.

下面 Java 内存模型一些`天然的`先行发生关系, 这些先行关系无序任何同步器协助就已经存在, 可以在编码中直接使用. 如果两个操作之间的关系不在此列, 且无法从下列规则中推导出来, 它们就没有顺序性的保证, 虚拟机可以对它们随意地进行重排序:

- `程序次序规则(Program Order Rule)`: 如果在`一个线程`内, 按照代码的顺序, 书写在前面的操作先行发生于书写在后面的操作.
- `管程锁定规则(Monitor Lock Rule)`: 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作. 这里的后面是指时间上的先后顺序.
- `volatile变量规则(Volatile Variable Rule)`: 对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作. 这里的后面同样指的是时间上的先后顺序.
- `线程启动规则(Thread StartRule)`: Thread 对象的 start()方法先行发生于该线程的每一个动作.
- `线程终止规则(Thread Termination Rule)`: 线程中所有的操作都先行发生于此线程的终止检测. 我们可以通过 Thread.join()方法结束, Thread.isAlive()的返回值等手段检测到线程已经终止执行.
- 线程中断规则(Thread Interruption Rule)`: 线程 interrupt()方法调用先行发生于被中断线程的代码检测到中断事件的发生. 可以通过 Thread.interrupted()方法检测到是否有中断发生.
- `对象终结规则(Finalizer Rule)`: 一个对象的初始化完成先行发生于它的 finalize()方法的开始.
- `传递性(Transitivity)`: 如果操作 A 先行发生于操作 B, 操作 B 先行发生于操作 C, 那就可以得出操作 A 先行发生于操作 C.

```java
private int value = 0;

public void setValue(int value) {
   this.value = value;
}

public int getValue() {
   return value;
}
```

如果线程 A 和线程 B, 线程 A 先(时间上先后)调用了`setValue(1)`, 然后线程 B 调用了同一个对象个`getValue()`方法, 那么线程 B 收到的返回值是什么?

我们依次来分析一下先行发生原则中的各项原则, 由于线程 A 和线程 B 不在同一个线程中, 第一个原则`程序次序原则`不成立. 也没有添加锁, 第二个原则`管程锁定原则`也不成立. 没有添加 volatile 关键词修饰, 第三个原则`volatile变量原则`也不成立. 后面的线程启动, 终止, 中断规则和对象的终结规则也和这个没有关系. 最后一条传递性规则也是不存在的. 没有一个适用的先行发生规则, 所以我们不能判断线程 A 的操作先行与线程 B 的操作(尽管时间上较前), 换句话说, 这里面的操作不是线程安全的, 我们无法确定线程 B 获得值是 1 还是 2.

时间上的先后顺序与先行关系原则之间, 基本没有太大关系, 我们衡量并发安全的时候, 不要受到时间顺序的干扰, 一切以先行顺序原则为准.

## Java 与线程

### 线程的实现

我们知道, 线程是比进程更加轻量级的调度执行单位, 线程的引入, 可以把一个进程的资源分配和执行调度分开, 各个线程既可以共享进程资源(内存地址, 文件 I/O 等), 又可以独立调度(线程是 CPU 调度的基本单位).

主流的操作系统都提供了线程实现, Java 语言则是提供了不同硬件和操作系统平台下对线程操作的统一处理, 每个已经执行 start()且尚未结束的 java.lang.Thread 类的实例就代表了一个线程. 查看 Thread 类的源码, 我们可以发现大多数关键的方法都是 Native 方法, 在 Java API 中, 一个 Native 方法往往代表着这个方法没有使用或无法使用平台无关的手段来实现(有时也是为了效率, 通常来说最高效率的手段也是平台相关的方法). 线程的实现方式主要有 3 种: 使用内核线程实现, 使用用户线程实现和使用过线程加轻量级进程的混合实现.

#### 使用内核线程实现

内核线程(Kernel-Level Thread, KLT)就是直接由操作系统内核(Kernel, 下称内核)支持的线程, 这种线程由内核来完成线程切换, 内核通过操纵调度器(Scheduler)对线程进行调度, 并负责将线程的任务映射到各个处理器上. 每个内核线程可以视为内核的一个分身, 这样操作系统就有能力同时处理多件事, 支持多线程的内核就叫做多线程内核(Multi-Threads Kernel).

程序一般都不会使用内核线程, 而是使用内核线程的一种高级接口: 轻量级进程(Light Weight Process), 轻量级进程就是我们通常意义上所讲的线程, 由于每个轻量级进程都由一个内核线程支持, 因此只有先支持内核线程, 才能有轻量级进程.

![show](https://image.cjyong.com/blog/jvm/30.png)

由于有内核线程的支持, 每个轻量级进程都成为了一个独立的调度单元, 即使有一个轻量级进程在系统调用中堵塞, 也不会影响整个进程继续工作, 但是轻量级进程也具有它的局限性: 首先, 由于是基于内核线程实现的, 所以各种线程操作, 如创建, 析构及同步, 都需要进行系统的调用. 而系统调用的代价相对较高, 需要在用户态(User Mode)和内核态(Kernel Mode)来回切换. 其次, 每个轻量级进程都需要有一个内核线程的支持, 因此轻量级进程需要消耗一定的内核资源(如内核线程的栈空间), 因此一个系统支持轻量级进程的数量是有限的.

#### 使用用户线程实现

广义上来说, 一个线程只要不是内核线程, 就可以认为是用户线程(User Thread UT), 因此, 从这个定义上来讲, 轻量级进程也属于用户线程, 但是轻量级进程的实现始终是建立在内核之上的, 许多操作都需要进行系统调用, 效率也会受到限制.

狭义上的用户线程指的是完全建立在用户空间的线程库上, 系统内核不能感知线程存在的实现. 用户线程的建立, 同步, 销毁和调度完全在用户态中完成, 不需要内核的帮助. 如果程序实现得当, 这种线程就不需要切换到内核态, 因此操作可以说是非常快速且低消耗的, 也可以支持规模更大的线程数量, 部分高性能数据中的多线程就是由用户线程实现的. 这种进程与用户之间 1 : N 的关系称为 1 对多的线程模型.

![show](https://image.cjyong.com/blog/jvm/10.jpg)

使用用户线程的优势在于不需要系统内核的支援, 劣势也是没有系统内核的支援, 所有的线程操作都需要用户程序自己完成. 线程的创建, 切换和调度都是需要考虑的问题, 而且由于操作系统只要把处理器资源分配到进程, 那诸如`堵塞如何处理`, `多处理器系统中如何映射到其他处理器`这类问题解决起来将会变得异常困难, 甚至不可能完成.

#### 使用用户线程加轻量级进程混合实现

线程除了依赖内核线程实现和完全由用户程序自己实现之外, 还有一种将内核线程与用户线程一起使用的方式. 在这种混合实现下, 既存在用户线程, 也存在轻量级进程. 用户线程还是建立在用户空间中, 因此用户线程的创建, 切换, 析构等操作依然廉价, 并且可以支持大规模的用户线程并发. 而操作系统提供的轻量级进程则是作为用户线程和内核线程之间的桥梁, 这样可以使用内核提供的线程调度功能和处理器映射, 并且用户线程的系统调用要通过轻量级线程来完成, 大大降低了整个进程被完全堵塞的风险. 在这种混合模式中, 用户线程与轻量级进程的数量比是不定的, 即为 N:M 的关系.

![show](https://image.cjyong.com/blog/jvm/11.jpg)

#### Java 线程的实现

对于 SUN JDK 来说, 它的 Windows 版本与 Linux 版本都是使用 1 对 1 的线程模型实现的, 即一条 Java 线程就映射到一条轻量级进程之中, 因为 Windows 和 Linux 系统提供的线程模型就是 1 对 1 的. 而在 Solaris 平台, 由于操作系统的线程特性可以同时支持 1 对 1 及多对多的线程模型, 因此在 Solaris 版的 JDK 中也对应提供了两个平台专有的虚拟机参数: -XX:+UseLWPSSynchronization(默认值)和-XX:+UseBoundThreads 来指明虚拟机使用哪种线程模型.

### Java 的线程调度

线程调度是指系统为线程分配处理器使用权的过程, 主要的调度方式有两种: 分别是`协同式线程调度(Cooperative Threads-Scheduling)`和`抢占式线程调度(Preemptive Threads-Scheduling)`.

如果使用协同式调度的多线程系统, 线程的执行时间由线程本身来控制, 线程把自己完成之后, 要主动通知系统切换到另一个线程上. 协同式多线程的好处就是实现简单, 而且由于线程要把自己的事情干完之后才会进行线程切换, 切换操作对于线程自己来说是可知的, 没有线程同步的问题. 缺点也很明显: 线程执行时间不可控制, 如果一个线程编写出现问题, 一直不告知系统进行线程切换, 那么程序就会一直堵塞在哪里. Windows3.x 系统就是使用协同式来实现多线程任务的, 非常不稳定, 一个进程坚持不让出 CPU 执行时间就可能会导致整个系统崩溃.

如果是抢占式调度的多线程系统, 那么每个线程将由系统来分配执行时间, 线程的切换不由线程本身决定(在 Java 中, Thread.yield()可以让出执行时间). 在这种实现线程调度的方式下, 线程的执行时间是系统可控的, 也不会有一个线程导致整个进程堵塞的问题. Java 中使用的线程调度就是抢占式调度.

虽然 Java 线程调度是由系统自动完成的, 但是我们可以`建议`系统给某些线程多分配一点时间, 另外一些线程则可以少分配一点: 我们可以通过设置线程的优先级来完成. Java 语言供设置了 10 个级别的优先级(Thread.MIN_PRIORITY 到 Thread.MAX_PRIORITY), 当两个线程都处在 Ready 状态下, 优先级高的线程更加容易被系统选择执行.

线程优先级并不是很靠谱, 原因是 Java 的线程时通过映射到系统的原生线程上来实现的 所以线程调度最终还是要取决于操作系统, 虽然很多操作系统都提供了线程优先级的概念, 但是并不见得所有能与 Java 线程的优先级一一对应, 如 Solaris 中有 2^32 种优先级, 但 Windows 只有 7 种, 比 Java 线程优先级多的系统还好说, 中间留空即可, 但是比 Java 线程优先级少的系统, 就不得不使用重复的优先级了.

![show](https://image.cjyong.com/blog/jvm/12.jpg)

另外优先级还有可能被系统自行改变. 如在 Windows 系统中存在一个称为`优先级推进器(Priority Boosting)`(可以关闭)的功能, 大致作用就是当系统发现一个线程执行得特别`勤奋努力`的话, 可能会越过线程优先级去为它分配执行时间. 因此我们不能在程序中通过优先级来完全准确地判断一组状态都为 Ready 的线程将会先执行那一个.

### 状态切换

![show](https://image.cjyong.com/blog/jvm/31.png)

Java 定义了 5 种线程状态, 在任意一个时间点, 一个线程只能有且只有其中一种状态, 这 5 中状态分别如下:

- 新建(New): 创建后尚未启动的线程就处于这个状态.
- 运行(Runnable): 包括了操作系统线程状态中的 Running 和 Ready, 也就是此状态的线程可能在执行, 也有可能在等待 CPU 分配执行时间.
- 无限期等待(Waiting): 处于这种状态的线程不会被分配 CPU 执行时间, 它们需要等待被其他线程显式唤醒. 以下方法会让线程陷入无限期的等待状态:
- 没有设置 Timeout 参数的 Object.wait()方法
- 没有设置 Timeout 参数的 Thread.join()方法
- LockSupport.park()方法
- 限期等待(Timed Waiting): 处于这种状态的线程不会被分配 CPU 执行时间, 它们不需要等待被其他线程显式唤醒, 到了一定时间之后, 它们会由系统自动唤醒. 以下方法会让线程陷入无限期的等待状态:
- Thead.sleep()方法
- 设置了 Timeout 参数的 Object.wait()方法
- 设置了 Timeout 参数的 Thread.join()方法
- LockSupport.parkNanos()方法
- LockSupport.parkUtil()方法
- 堵塞(Blocked): 线程被堵塞了, `堵塞状态`与`等待状态`的区别在于: `堵塞状态`在等待获取到一个排他锁, 这个事件在另外一个线程放弃这个锁的时候发生; 而`等待状态`则是等待一段时间或者唤醒动作的发生. 在程序等待进入同步区域的时候, 线程将进入这种状态.
- 结束(Terminated): 已终止线程的线程状态, 线程已经结束运行.
